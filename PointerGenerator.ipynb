{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointer Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PICOHelper import get_pico_datasets\n",
    "from NewsroomHelper import get_newsroom_datasets\n",
    "from models import PointerGeneratorModel\n",
    "from model_helpers import loss_function, error_function\n",
    "from utils import get_index_words, produce_attention_visualization_file\n",
    "from pytorch_helper import VariableBatchDataLoader, ModelManipulator, plot_learning_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 1e-2\n",
    "# INITIAL_ACCUMULATOR_VALUE = 0.1\n",
    "GAMMA = 1\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "BEAM_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11029 3676 3678\n",
      "retrieving word2vec model from file\n"
     ]
    }
   ],
   "source": [
    "# pico_dataset_train, pico_dataset_dev, pico_dataset_test = get_pico_datasets()\n",
    "newsroom_dataset_train, newsroom_dataset_dev, newsroom_dataset_test = get_newsroom_datasets(with_oov=True)\n",
    "word_vectors = newsroom_dataset_train.word_vectors\n",
    "start_index = newsroom_dataset_train.word_indices['<start>']\n",
    "end_index = newsroom_dataset_train.word_indices['<end>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer_generator_model = PointerGeneratorModel(word_vectors, start_index, end_index, num_hidden1=None, num_hidden2=None, with_coverage=False, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = VariableBatchDataLoader(newsroom_dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "optimizer = torch.optim.Adam(pointer_generator_model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "# optimizer = torch.optim.Adagrad((pointer_generator_model.cuda() if USE_CUDA else pointer_generator_model).parameters(),\n",
    "#                                 lr=LEARNING_RATE, initial_accumulator_value=INITIAL_ACCUMULATOR_VALUE)\n",
    "model_manip = ModelManipulator(pointer_generator_model, optimizer, loss_function, error_function, use_cuda=USE_CUDA)\n",
    "train_stats, val_stats = model_manip.train(dataloader, NUM_EPOCHS, dataset_val=newsroom_dataset_dev, stats_every=10, verbose_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pointer_generator_model, 'models/pointer_generator_temp.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jered/Documents/Projects/Summarization/venv/lib/python3.6/site-packages/torch/serialization.py:425: SourceChangeWarning: source code of class 'models.PointerGeneratorModel' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
      "  warnings.warn(msg, SourceChangeWarning)\n"
     ]
    }
   ],
   "source": [
    "pointer_generator_model = torch.load('models/pointer_generator_temp.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(training_values=train_stats, validation_values=val_stats, figure_name='graphs/pointer_generator_training_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = newsroom_dataset_dev[2:3]\n",
    "results, oov_indices = pointer_generator_model(batch['text'].cuda(), batch['text_length'].cuda(), batch['text_oov_indices'], beam_size=BEAM_SIZE)\n",
    "# generated_output = generator_model(batch['text'], batch['text_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text ['<start>', 'by', 'meredith', 'mandell', ',', 'special', 'for', 'usa', 'today', 'one', 'survivor', 'dies', 'in', 'israel', 'every', 'hour', ',', 'according', 'to', 'the', 'foundation', 'for', 'the', 'benefit', 'of', 'holocaust', 'survivors', 'in', 'israel', '.', 'president', 'mahmoud', 'ahmadinejad', 'claims', 'that', 'israel', 'is', 'bluffing', 'when', 'it', 'threatens', 'to', 'bomb', 'iran', \"'s\", 'nuclear', 'sites', 'to', 'stop', 'tehran', 'from', 'building', 'its', 'first', 'atomic', 'bomb', '.', 'iran', 'insists', 'its', 'nuclear', 'program', 'is', 'peaceful', ',', 'focused', 'on', 'generating', 'power', 'to', 'boost', 'its', 'economy', '.', 'sept', 'qqq', '(', 'reuters', ')', '-', 'israeli', 'president', 'shimon', 'peres', 'offered', 'his', 'iranian', 'counterpart', ',', 'mahmoud', 'ahmadinejad', ',', 'a', 'history', 'lesson', 'on', 'thursday', ',', 'saying', 'his', 'lack', 'of', 'knowledge', 'about', 'the', 'region', 'was', 'an', 'embarrassment', '.', 'the', 'outspoken', 'iranian', 'leader', 'raised', 'hackles', 'in', 'israel', 'by', 'car', 'in', 'a', 'protected', 'motorcade', 'on', 'wednesday', ',', 'new', 'york', 'police', 'department', 'spokesman', 'paul', 'browne', 'said', '.', 'iranian', 'president', 'mahmoud', 'ahmadinejad', 'addressed', 'the', 'u.n.', 'general', 'assembly', 'on', 'wednesday', '.', 'iranian', 'officials', 'said', 'the', 'incident', 'took', 'place', 'during', 'a', 'protest', 'against', 'protester', 'speaks', 'before', 'hundreds', 'of', 'demonstrators', 'at', 'a', 'podium', 'near', 'a', 'giant', 'effigy', 'of', 'iranian', 'president', 'mahmoud', 'ahmadinejad', 'outside', 'the', 'un', 'headquarters', 'building', 'in', 'new', 'york', ',', 'us', ',', 'on', 'wednesday', '(', 'thursday', 'in', 'jakarta', ')', '.', 'the', 'protesters', 'came', 'from', 'different', 'groups', 'with', 'by', 'george', 'jahn', ',', 'associated', 'press', 'a', 'senior', 'u.n.', 'nuclear', '-', 'agency', 'team', 'will', 'visit', 'tehran', 'on', 'jan.', 'qqq', ',', 'with', 'iran', 'saying', 'it', 'is', 'ready', 'after', 'years', 'of', 'refusal', 'to', 'discuss', 'allegations', 'that', 'it', 'was', 'involved', 'in', 'secret', 'nuclear', '-', 'weapons', 'work', ',', 'diplomats', 'said', 'thursday', '.', 'by', 'cal', 'thomas', 'and', 'bob', 'beckel', 'the', 'economy', 'will', 'heal', 'or', 'not', '.', 'will', 'obamacare', 'live', 'or', 'die', '?', 'and', 'what', 'of', 'the', 'kardashians', '?', 'into', 'the', 'crystal', 'ball', 'we', 'go', '<end>']\n",
      "reference summary ['<start>', 'collection', 'of', 'all', 'usatoday.com', 'coverage', 'of', 'mahmoud', 'ahmadinejad', ',', 'including', 'articles', ',', 'videos', ',', 'photos', ',', 'and', 'quotes', '.', '<end>']\n",
      "decoded summary ['<start>', 'by', 'meredith', 'meredith', ',', 'meredith', ',', 'including', 'articles', ',', 'videos', ',', 'videos', ',', 'videos', ',', 'photos', ',', 'and', 'quotes', '.', '<end>']\n",
      "tensor(1.2749, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss, summary_info = results[0]\n",
    "for i in range(len(summary_info[0])):\n",
    "    summary_indices, summary_length = summary_info[0][i], summary_info[1][i]\n",
    "    r_summary_indices, r_summary_length = batch['summary'][i].numpy(), batch['summary_length'][i].numpy()\n",
    "    text_indices, text_length = batch['text'][i].numpy(), batch['text_length'][i].numpy()\n",
    "    oov_words = {v:k for k,v in batch['text_oov_indices'][i].items()}\n",
    "    \n",
    "    text = get_index_words(text_indices[:text_length], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "    reference_summary = get_index_words(r_summary_indices[:r_summary_length], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "    decoded_summary = get_index_words(summary_indices[:summary_length], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "    print(\"text\", text)\n",
    "    print(\"reference summary\", reference_summary)\n",
    "    print(\"decoded summary\", decoded_summary)\n",
    "    print(loss[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, summary_info = results[0]\n",
    "i = 0\n",
    "\n",
    "summary_indices, summary_length = summary_info[0][i], summary_info[1][i]\n",
    "attentions, p_gens = [[float(f) for f in vector] for vector in summary_info[3][i]], [float(f) for f in summary_info[4][i]]\n",
    "r_summary_indices, r_summary_length = batch['summary'][i].numpy(), batch['summary_length'][i].numpy()\n",
    "text_indices, text_length = batch['text'][i].numpy(), batch['text_length'][i].numpy()\n",
    "oov_words = {v:k for k,v in batch['text_oov_indices'][i].items()}\n",
    "\n",
    "text = get_index_words(text_indices[:text_length], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "reference_summary = get_index_words(r_summary_indices[:r_summary_length], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "decoded_summary = get_index_words(summary_indices[:summary_length], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "produce_attention_visualization_file('graphs/attn_vis_data.json', text, decoded_summary, reference_summary, attentions, p_gens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
