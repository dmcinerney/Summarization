{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointer Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PICOHelper import get_pico_datasets\n",
    "from NewsroomHelper import get_newsroom_datasets\n",
    "from models import Summarizer\n",
    "from model_helpers import loss_function, error_function\n",
    "from utils import get_index_words, produce_attention_visualization_file\n",
    "from pytorch_helper import VariableBatchDataLoader, ModelManipulator, plot_learning_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 2\n",
    "LEARNING_RATE = 1e-2\n",
    "# INITIAL_ACCUMULATOR_VALUE = 0.1\n",
    "GAMMA = 1\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "BEAM_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11029 3676 3678\n",
      "retrieving word2vec model from file\n"
     ]
    }
   ],
   "source": [
    "# pico_dataset_train, pico_dataset_dev, pico_dataset_test = get_pico_datasets()\n",
    "newsroom_dataset_train, newsroom_dataset_dev, newsroom_dataset_test = get_newsroom_datasets(with_oov=True)\n",
    "word_vectors = newsroom_dataset_train.word_vectors\n",
    "start_index = newsroom_dataset_train.word_indices['<start>']\n",
    "end_index = newsroom_dataset_train.word_indices['<end>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer_generator_model = Summarizer(word_vectors, start_index, end_index, num_hidden1=None, num_hidden2=None, with_coverage=True, gamma=GAMMA, with_pointer=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = VariableBatchDataLoader(newsroom_dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "optimizer = torch.optim.Adam(pointer_generator_model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "# optimizer = torch.optim.Adagrad((pointer_generator_model.cuda() if USE_CUDA else pointer_generator_model).parameters(),\n",
    "#                                 lr=LEARNING_RATE, initial_accumulator_value=INITIAL_ACCUMULATOR_VALUE)\n",
    "model_manip = ModelManipulator(pointer_generator_model, optimizer, loss_function, error_function, use_cuda=USE_CUDA)\n",
    "train_stats, val_stats = model_manip.train(dataloader, NUM_EPOCHS, dataset_val=newsroom_dataset_dev, stats_every=10, verbose_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pointer_generator_model, 'models/pointer_generator_temp.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer_generator_model = torch.load('models/pointer_generator_temp.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(training_values=train_stats, validation_values=val_stats, figure_name='graphs/pointer_generator_training_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jered/Documents/Projects/Summarization/submodules.py:21: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, (h, c) = self.lstm(x)\n"
     ]
    }
   ],
   "source": [
    "batch = newsroom_dataset_dev[3:4]\n",
    "results, oov_indices = pointer_generator_model(batch['text'].cuda(), batch['text_length'].cuda(), batch['text_oov_indices'], beam_size=BEAM_SIZE)\n",
    "# generated_output = generator_model(batch['text'], batch['text_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text ['<start>', 'new', 'york', 'city', 'detectives', 'on', 'tuesday', 'released', 'the', 'name', 'of', 'a', 'man', 'seen', 'leaving', 'the', 'bronx', 'subway', 'station', 'where', 'a', 'rider', 'was', 'pushed', 'to', 'his', 'death', 'over', 'the', 'weekend', '.', 'the', 'man', 'being', 'sought', 'by', 'police', ',', 'kevin', 'darden', ',', 'qqq', ',', 'was', 'described', 'as', 'a', 'person', 'of', 'interest', 'in', 'the', 'killing', '–', 'not', 'as', 'a', 'suspect', '–', 'and', 'detectives', 'were', '“', 'endeavoring', 'to', 'locate', '”', 'him', 'for', 'questioning', ',', 'according', 'to', 'a', 'poster', 'seeking', 'information', '.', 'the', 'police', 'said', 'investigators', 'believed', 'mr.', 'darden', 'was', 'the', 'man', 'seen', 'on', 'surveillance', 'video', 'walking', 'calmly', 'from', 'the', 'qqq', 'street', 'subway', 'station', 'where', 'the', 'rider', ',', 'wai', 'kuen', 'kwok', ',', 'qqq', ',', 'was', 'shoved', 'into', 'the', 'path', 'of', 'an', 'oncoming', 'subway', 'car', 'on', 'sunday', 'morning', '.', 'mr.', 'kwok', 'had', 'been', 'standing', 'on', 'the', 'platform', 'with', 'his', 'wife', 'at', 'the', 'time', '.', 'other', 'riders', 'on', 'the', 'platform', 'did', 'not', 'see', 'the', 'shove', 'but', 'told', 'the', 'police', 'that', 'the', 'man', 'they', 'saw', 'rapidly', 'leaving', 'the', 'station', 'was', 'the', 'same', 'man', 'on', 'the', 'surveillance', 'video', ',', 'seen', 'boarding', 'a', 'bus', 'two', 'minutes', 'later', '.', 'no', 'probable', 'cause', 'yet', 'exists', 'for', 'an', 'arrest', 'of', 'mr.', 'darden', ',', 'according', 'to', 'the', 'police', 'department', 'poster', 'naming', 'him', 'as', 'a', 'person', 'seen', 'leaving', 'the', 'station', '.', 'the', 'killing', 'rattled', 'riders', 'across', 'the', 'subway', 'system', 'and', 'immediately', 'raised', 'questions', 'about', 'a', 'motive', 'for', 'the', 'apparently', 'random', 'attack', '.', 'mr.', 'kwok', '’s', 'wife', ',', 'yow', 'ho', 'lee', ',', 'qqq', ',', 'told', 'investigators', 'that', 'the', 'man', 'who', 'attacked', 'her', 'husband', 'said', 'nothing', 'before', 'suddenly', 'shoving', 'mr.', 'kwok', 'and', 'fleeing', '.', 'for', 'several', 'minutes', 'afterward', ',', 'the', 'man', 'who', 'would', 'soon', 'be', 'the', 'subject', 'of', 'a', 'manhunt', 'by', 'the', 'police', 'appeared', 'to', 'behave', 'as', 'if', 'nothing', 'out', 'of', 'the', 'ordinary', 'had', 'happened', '.', 'he', 'boarded', 'a', 'local', 'bus', 'just', 'outside', 'the', 'qqq', 'street', 'station', 'in', 'the', 'bronx', ',', 'quietly', 'taking', 'a', 'seat', 'at', 'the', 'back', '.', 'he', 'did', 'not', 'react', 'when', 'other', 'passengers', ',', 'stranded', 'by', 'the', 'stalled', 'trains', 'below', ',', 'boarded', 'the', 'same', 'bus', 'talking', 'about', 'the', 'deadly', 'push', '.', 'he', 'stepped', 'off', 'the', 'bus', 'several', 'blocks', 'away', 'and', 'smoked', 'a', 'cigarette', '.', 'from', 'surveillance', 'video', ',', 'detectives', 'followed', 'his', 'movements', 'to', 'the', 'sidewalk', 'outside', 'a', 'deli', 'on', 'jesup', 'avenue', '.', 'then', 'he', 'disappeared', '.', 'but', 'despite', 'what', 'was', 'described', 'as', 'a', '“', 'qqq', 'operation', ',', '”', 'the', 'search', 'by', 'the', 'police', ',', 'aided', 'by', 'the', 'new', 'york', '/', 'new', 'jersey', 'regional', 'fugitive', 'task', 'force', ',', 'the', 'man', 'remained', 'at', 'large', 'on', 'monday', 'night', '.', 'mr.', 'darden', ',', 'whose', 'last', 'known', 'address', 'is', 'two', 'miles', 'north', 'of', 'the', 'subway', 'station', ',', 'has', 'an', 'extensive', 'history', 'of', 'arrests', ',', 'most', 'recently', 'on', 'nov.', 'qqq', 'in', 'manhattan', 'on', 'a', 'pickpocketing', 'charge', '.', 'he', 'was', 'identified', ',', 'the', 'police', 'said', ',', 'by', 'a', 'detective', 'who', 'believed', 'he', 'recognized', 'the', 'image', 'of', 'the', 'man', 'on', 'the', 'surveillance', 'footage', 'and', 'pieced', 'together', 'his', 'identification', 'from', 'arrest', 'photographs', 'and', 'other', 'information', '.', '<end>']\n",
      "reference summary ['<start>', 'new', 'york', 'city', 'detectives', 'are', 'trying', 'to', 'find', 'kevin', 'darden', ',', 'qqq', ',', 'who', 'they', 'believe', 'was', 'seen', 'leaving', 'the', 'subway', 'station', 'where', 'a', 'rider', 'was', 'pushed', 'to', 'his', 'death', 'on', 'sunday', '.', '<end>']\n",
      "decoded summary ['<start>', 'new', 'york', 'city', 'detectives', 'on', 'the', 'name', 'of', 'a', 'rider', 'was', 'pushed', 'to', 'his', 'death', 'over', 'the', 'weekend', '–', 'a', 'qqq', 'in', 'the', 'bronx', 'subway', 'station', '.', '<end>']\n",
      "tensor(1.1541, device='cuda:0', grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "loss, summary_info = results[0]\n",
    "for i in range(len(summary_info[0])):\n",
    "    summary_indices, summary_length = summary_info[0][i], summary_info[1][i]\n",
    "    r_summary_indices, r_summary_length = batch['summary'][i].numpy(), batch['summary_length'][i].numpy()\n",
    "    text_indices, text_length = batch['text'][i].numpy(), batch['text_length'][i].numpy()\n",
    "    oov_words = {v:k for k,v in batch['text_oov_indices'][i].items()}\n",
    "    \n",
    "    text = get_index_words(text_indices[:text_length], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "    reference_summary = get_index_words(r_summary_indices[:r_summary_length], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "    decoded_summary = get_index_words(summary_indices[:summary_length], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "    print(\"text\", text)\n",
    "    print(\"reference summary\", reference_summary)\n",
    "    print(\"decoded summary\", decoded_summary)\n",
    "    print(loss[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, summary_info = results[0]\n",
    "i = 0\n",
    "\n",
    "summary_indices, summary_length = summary_info[0][i], summary_info[1][i]\n",
    "attentions, p_gens = [[float(f) for f in vector[1:-1]] for vector in summary_info[3][i][:-1]], [float(f) for f in summary_info[4][i][:-1]]\n",
    "r_summary_indices, r_summary_length = batch['summary'][i].numpy(), batch['summary_length'][i].numpy()\n",
    "text_indices, text_length = batch['text'][i].numpy(), batch['text_length'][i].numpy()\n",
    "oov_words = {v:k for k,v in batch['text_oov_indices'][i].items()}\n",
    "\n",
    "text = get_index_words(text_indices[1:text_length-1], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "reference_summary = get_index_words(r_summary_indices[1:r_summary_length-1], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "decoded_summary = get_index_words(summary_indices[1:summary_length-1], newsroom_dataset_train.words, oov_words=oov_words)\n",
    "produce_attention_visualization_file('graphs/attn_vis_data.json', text, decoded_summary, \" \".join(reference_summary), attentions, p_gens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
