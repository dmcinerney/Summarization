{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PICOHelper import get_pico_datasets\n",
    "from NewsroomHelper import get_newsroom_datasets\n",
    "from SummarizationModelStructures import PointerGeneratorModel, loss_function, error_function\n",
    "from utils import get_index_words\n",
    "from pytorch_helper import VariableBatchDataLoader, ModelManipulator, plot_learning_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 1e-2\n",
    "# INITIAL_ACCUMULATOR_VALUE = 0.1\n",
    "GAMMA = 1\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pico_dataset_train, pico_dataset_dev, pico_dataset_test = get_pico_datasets()\n",
    "newsroom_dataset_train, newsroom_dataset_dev, newsroom_dataset_test = get_newsroom_datasets(with_oov=True)\n",
    "word_vectors = newsroom_dataset_train.word_vectors\n",
    "start_index = newsroom_dataset_train.word_indices['<start>']\n",
    "end_index = newsroom_dataset_train.word_indices['<end>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer_generator_model = PointerGeneratorModel(word_vectors, start_index, end_index, num_hidden1=None, num_hidden2=None, with_coverage=False, gamma=GAMMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = VariableBatchDataLoader(newsroom_dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "optimizer = torch.optim.Adam(pointer_generator_model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "# optimizer = torch.optim.Adagrad((pointer_generator_model.cuda() if USE_CUDA else pointer_generator_model).parameters(),\n",
    "#                                 lr=LEARNING_RATE, initial_accumulator_value=INITIAL_ACCUMULATOR_VALUE)\n",
    "model_manip = ModelManipulator(pointer_generator_model, optimizer, loss_function, error_function, use_cuda=USE_CUDA)\n",
    "train_stats, val_stats = model_manip.train(dataloader, NUM_EPOCHS, dataset_val=newsroom_dataset_dev, stats_every=10, verbose_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pointer_generator_model, 'data/pointer_generator_test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pointer_generator_model = torch.load('data/pointer_generator_test.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(training_values=train_stats, validation_values=val_stats, figure_name='pointer_generator_training_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = newsroom_dataset_dev[0:5]\n",
    "loss, summary_info, oov_indices = pointer_generator_model(batch['text'].cuda(), batch['text_length'].cuda(), batch['text_oov_indices'])\n",
    "# generated_output = generator_model(batch['text'], batch['text_length'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,indices in enumerate(summary_info[0]):\n",
    "    oov_words = {v:k for k,v in oov_indices[i].items()}\n",
    "    text, l = batch['text'][i], batch['text_length'][i]\n",
    "    print(\"text\", get_index_words(text[:l].numpy(), newsroom_dataset_train.words, oov_words=oov_words))\n",
    "    text, l = batch['summary'][i], batch['summary_length'][i]\n",
    "    print(\"summary\", get_index_words(text[:l].numpy(), newsroom_dataset_train.words, oov_words=oov_words))\n",
    "    print(\"generated summary\", get_index_words(indices[:summary_info[1][i]], newsroom_dataset_train.words, oov_words=oov_words))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
