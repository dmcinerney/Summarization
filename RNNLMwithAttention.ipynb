{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PICOHelper import get_pico_datasets\n",
    "from NewsroomHelper import get_newsroom_datasets\n",
    "from models import Summarizer\n",
    "from model_helpers import loss_function, error_function\n",
    "from utils import get_index_words, produce_attention_visualization_file, summarize, get_text_triplets, produce_batch_summary_files\n",
    "from pytorch_helper import VariableBatchDataLoader, ModelManipulator, plot_learning_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# training parameters\n",
    "BATCH_SIZE = 64\n",
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 1e-3\n",
    "# INITIAL_ACCUMULATOR_VALUE = 0.1\n",
    "GAMMA = 1\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)\n",
    "BEAM_SIZE = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11029 3676 3678\n",
      "retrieving word2vec model from file\n"
     ]
    }
   ],
   "source": [
    "# pico_dataset_train, pico_dataset_dev, pico_dataset_test = get_pico_datasets()\n",
    "newsroom_dataset_train, newsroom_dataset_dev, newsroom_dataset_test, preprocessor = get_newsroom_datasets()\n",
    "word_vectors = preprocessor.word_vectors\n",
    "start_index = preprocessor.word_indices['<start>']\n",
    "end_index = preprocessor.word_indices['<end>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model = Summarizer(preprocessor, start_index, end_index, num_hidden1=None, num_hidden2=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloader = VariableBatchDataLoader(newsroom_dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "optimizer = torch.optim.Adam(generator_model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "# optimizer = torch.optim.Adagrad((generator_model.cuda() if USE_CUDA else generator_model).parameters(),\n",
    "#                                 lr=LEARNING_RATE, initial_accumulator_value=INITIAL_ACCUMULATOR_VALUE)\n",
    "model_manip = ModelManipulator(generator_model, optimizer, loss_function, error_function, use_cuda=USE_CUDA)\n",
    "train_stats, val_stats = model_manip.train(dataloader, NUM_EPOCHS, dataset_val=newsroom_dataset_dev, stats_every=10, verbose_every=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator_model, 'models/generator_temp.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model = torch.load('models/generator_temp.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(training_values=train_stats, validation_values=val_stats, figure_name='graphs/generator_training_temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jered/Documents/Projects/Summarization/submodules.py:23: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "  output, (h, c) = self.lstm(x)\n"
     ]
    }
   ],
   "source": [
    "batch = newsroom_dataset_train[0:4]\n",
    "results = summarize(batch, generator_model, beam_size=BEAM_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text ['<start>', 'tuesday', ',', 'march', 'qqq', ',', 'qqq', ',', 'qqq', 'pm', 'apple', \"'s\", 'ceo', 'tim', 'cook', 'finally', 'revealed', 'the', 'tech', 'specs', 'for', 'the', 'highly', 'anticipated', 'apple', 'watch', 'monday', 'in', 'san', 'francisco', ',', 'when', 'he', 'announced', 'the', 'smartwatch', 'will', 'begin', 'shipping', 'april', 'qqq', 'and', 'starts', 'at', '$', 'qqq', '.', 'the', 'apple', 'watch', 'will', 'come', 'in', 'two', 'different', 'retina', 'displays', ',', 'qqq', 'and', 'qqq', ',', 'and', 'it', \"'ll\", 'have', 'a', 'battery', 'that', 'lasts', 'up', 'to', 'qqq', 'hours', '.', 'the', 'watch', 'will', 'also', 'come', 'in', 'four', 'different', 'colors', 'and', 'three', 'different', 'models', ':', 'apple', 'watch', 'sport', ',', 'apple', 'watch', 'and', 'apple', 'watch', 'edition', '.', 'compared', 'to', 'other', 'watches', 'like', 'the', 'samsung', 'gear', 's', 'and', 'the', 'moto', 'qqq', ',', 'the', 'apple', 'watch', 'is', 'capable', 'of', 'doing', 'the', 'same', 'basic', 'things', 'such', 'as', 'receive', 'messages', 'and', 'calls', ',', 'feature', 'calendar', 'notifications', 'and', 'double', 'as', 'a', 'fitness', 'tracker', '.', 'apple', 'is', 'a', 'oov', 'in', 'the', 'smartwatch', 'competition', ',', 'but', 'it', \"'ll\", 'still', 'be', 'a', 'viable', 'competitor', 'in', 'the', 'market', 'since', 'the', 'apple', 'watch', 'is', 'specifically', 'tailored', 'for', 'iphone', 'users', '.', 'the', 'daily', 'news', 'created', 'an', 'infographic', 'that', 'highlights', 'all', 'smartwatches', \"'\", 'tech', 'specs', 'including', 'prices', ',', 'weight', ',', 'displays', 'and', 'battery', 'life', '—', 'which', 'may', 'vary', 'depending', 'on', 'use', '.', 'if', 'you', \"'re\", 'thinking', 'of', 'getting', 'a', 'smartwatch', ',', 'this', 'infographic', 'might', 'just', 'help', 'you', 'get', 'a', 'better', 'sense', 'of', 'your', 'options', '.', 'this', 'is', 'how', 'the', 'apple', 'watch', \"'s\", 'tech', 'specs', 'compare', 'to', 'other', 'smartwatches', ':', '<end>']\n",
      "reference summary ['<start>', 'the', 'daily', 'news', 'created', 'an', 'infographic', 'that', 'highlights', 'all', 'smartwatches', \"'\", 'tech', 'specs', ',', 'including', 'the', 'apple', 'watch', '.', '<end>']\n",
      "decoded summary ['<start>', 'the', 'qqq', ',', ',', '<end>']\n",
      "3.10926\n",
      "text ['<start>', 'oov', ',', 'tenn.', '(', 'ap', ')', '\\x97', 'discount', '-', 'store', 'operator', 'plans', 'to', 'open', 'qqq', 'stores', 'and', 'hire', 'more', 'than', 'qqq', 'workers', 'in', 'qqq', '.', 'the', 'company', 'said', 'monday', 'the', 'store', 'openings', 'will', 'be', 'in', 'qqq', 'states', 'it', 'currently', 'operates', 'in', 'as', 'well', 'as', 'in', 'three', 'new', 'states', ':', 'connecticut', ',', 'nevada', 'and', 'new', 'hampshire', '.', 'it', 'also', 'plans', 'to', 'remodel', 'or', 'relocate', 'qqq', 'stores', '.', 'dollar', 'general', ',', 'based', 'in', 'oov', ',', 'tenn.', ',', 'currently', 'operates', 'qqq', 'stores', 'and', 'employs', 'qqq', 'staffers', '.', 'its', 'stores', 'have', 'gained', 'market', 'share', 'from', 'competitors', 'such', 'as', 'wal', '-', 'mart', 'stores', ',', 'as', 'consumers', 'count', 'pennies', 'because', 'of', 'high', 'unemployment', 'and', 'the', 'uncertain', 'economy', '.', 'in', 'december', 'dollar', 'general', 'said', 'its', 'third', '-', 'quarter', 'net', 'income', 'rose', 'qqq', '%', ',', 'helped', 'by', 'cost', 'cuts', 'and', 'higher', 'revenue', ',', 'and', 'the', 'company', 'raised', 'its', 'full', '-', 'year', 'guidance', '.', 'its', 'revenue', 'rose', 'qqq', '%', 'to', '$', 'qqq', 'billion', '.', 'you', 'share', 'in', 'the', 'usa', 'today', 'community', ',', 'so', 'please', 'keep', 'your', 'comments', 'smart', 'and', 'civil', '.', 'do', \"n't\", 'attack', 'other', 'readers', 'personally', ',', 'and', 'keep', 'your', 'language', 'decent', '.', 'use', 'the', '\"', 'report', 'abuse', '\"', 'button', 'to', 'make', 'a', 'difference', '.', '<end>']\n",
      "reference summary ['<start>', 'discount', '-', 'store', 'operator', 'dollar', 'general', 'plans', 'to', 'open', 'qqq', 'stores', 'and', 'hire', 'more', 'than', 'qqq', 'workers', 'in', 'qqq', '.', '<end>']\n",
      "decoded summary ['<start>', 'the', 'qqq', ',', ',', 'the', 'the', 'qqq', '.', '<end>']\n",
      "2.94712\n",
      "text ['<start>', 'culture', 'connoisseurs', 'consistently', 'offer', 'thought', '-', 'provoking', ',', 'timely', 'comments', 'on', 'the', 'arts', ',', 'lifestyle', 'and', 'entertainment', '.', 'more', 'about', 'badges', '|', 'request', 'a', 'badge', 'washingtologists', 'consistently', 'post', 'thought', '-', 'provoking', ',', 'timely', 'comments', 'on', 'events', ',', 'communities', ',', 'and', 'trends', 'in', 'the', 'washington', 'area', '.', 'more', 'about', 'badges', '|', 'request', 'a', 'badge', 'this', 'commenter', 'is', 'a', 'washington', 'post', 'editor', ',', 'reporter', 'or', 'producer', '.', 'this', 'commenter', 'is', 'a', 'washington', 'post', 'contributor', '.', 'post', 'contributors', 'are', 'n’t', 'staff', ',', 'but', 'may', 'write', 'articles', 'or', 'columns', '.', 'in', 'some', 'cases', ',', 'contributors', 'are', 'sources', 'or', 'experts', 'quoted', 'in', 'a', 'story', '.', 'more', 'about', 'badges', '|', 'request', 'a', 'badge', 'washington', 'post', 'reporters', 'or', 'editors', 'recommend', 'this', 'comment', 'or', 'reader', 'post', '.', 'you', 'must', 'be', 'logged', 'in', 'to', 'report', 'a', 'comment', '.', 'you', 'must', 'be', 'logged', 'in', 'to', 'recommend', 'a', 'comment', '.', '<end>']\n",
      "reference summary ['<start>', 'at', 'this', 'year', '’s', 'worldwide', 'developers', 'conference', 'in', 'san', 'francisco', ',', 'calif.', ',', 'the', 'tech', 'giant', 'rolled', 'out', 'new', 'versions', 'of', 'its', 'macbook', 'pro', 'laptops', 'and', 'its', 'mountain', 'lion', 'operating', 'system', '.', '<end>']\n",
      "decoded summary ['<start>', 'the', 'qqq', '.', '<end>']\n",
      "2.90863\n",
      "text ['<start>', 'los', 'angeles', '—', '\"', 'i', 'do', \"n't\", 'understand', 'award', 'shows', ',', '\"', 'kanye', 'west', 'admitted', 'sunday', 'at', 'the', 'mtv', 'video', 'music', 'awards', '.', 'but', 'awards', 'shows', 'sure', 'do', 'understand', 'him', '.', 'west', 'tends', 'to', 'bring', 'ratings', 'and', 'ignite', 'conversations', 'all', 'over', 'social', 'media', '—', 'so', 'much', 'so', 'that', 'he', 'helped', 'this', 'year', \"'s\", 'vmas', 'break', 'twitter', \"'s\", 'record', 'for', 'the', 'most', 'tweets', 'sent', 'about', 'a', 'non', '-', 'sports', 'program', 'in', 'the', 'united', 'states', '.', 'the', 'broadcast', 'generated', 'qqq', 'million', 'tweets', ',', 'up', 'from', 'qqq', 'million', 'in', 'qqq', '.', 'nielsen', 'social', ',', 'which', 'has', 'been', 'tracking', 'twitter', 'activity', 'for', 'television', 'since', 'qqq', ',', 'reported', 'the', 'record', '-', 'breaking', 'data', 'monday', '.', 'those', 'qqq', 'million', 'tweets', 'were', 'sent', 'by', 'qqq', 'million', 'people', ',', 'and', 'nearly', 'qqq', 'million', 'people', 'saw', 'those', 'tweets', 'qqq', 'million', 'times', '.', 'in', 'comparison', ',', 'this', 'year', \"'s\", 'grammys', 'attracted', 'qqq', 'million', 'tweets', '.', 'the', 'super', 'bowl', ',', 'which', 'is', 'considered', 'a', 'sports', 'program', ',', 'incited', 'qqq', 'million', 'tweets', 'in', 'february', '.', 'the', 'top', '-', 'tweeted', 'vmas', 'minute', 'came', 'at', 'qqq', 'p.m.', 'et', '(', 'qqq', 'tweets', ')', 'when', 'west', 'announced', 'that', 'he', \"'s\", 'running', 'for', 'running', 'for', 'president', 'in', 'qqq', '.', 'he', 'jokingly', '(', 'maybe', ')', 'revealed', 'his', 'bid', 'and', 'dropped', 'the', 'mic', 'to', 'wrap', 'up', 'his', 'acceptance', 'speech', 'for', 'the', 'michael', 'jackson', 'video', 'vanguard', 'award', '.', 'does', 'he', 'have', 'your', 'vote', 'america', '?', '@kanyewest', 'accepts', 'the', 'video', 'vanguard', 'award', 'qqq', '—', 'mtv', '(', 'oov', ')', 'august', 'qqq', ',', 'qqq', '\"', 'it', 'do', \"n't\", 'matter', ',', 'though', '.', 'it', 'ai', \"n't\", 'about', 'me', '.', 'it', \"'s\", 'about', 'ideas', ',', 'people', 'who', 'believe', 'in', 'truth', '.', 'and', 'yes', ',', 'as', 'you', 'probably', 'could', \"'ve\", 'guessed', 'by', 'this', 'moment', ',', 'i', 'have', 'decided', 'in', 'qqq', 'to', 'run', 'for', 'president', ',', '\"', 'kanye', 'said', 'to', 'a', 'stunned', 'crowd', 'that', 'included', 'his', 'wife', ',', 'kim', 'kardashian', '.', 'the', 'night', 'was', 'filled', 'with', 'similarly', 'buzzy', 'moments', ',', 'including', 'taylor', 'swift', 'appearing', 'during', 'nicki', 'minaj', \"'s\", 'opening', 'number', ',', 'minaj', 'and', 'miley', 'cyrus', \"'s\", 'onstage', 'verbal', 'spat', ',', 'and', 'justin', 'bieber', \"'s\", 'post', '-', 'performance', 'tears', '.', 'but', 'the', 'hottest', 'talking', 'point', 'of', 'the', 'night', 'was', 'kanye', \"'s\", 'presidential', 'bid', ',', 'as', 'viewers', 'feverishly', 'spread', 'the', 'news', ',', 'created', 'instant', 'memes', 'and', 'tried', 'to', 'predict', 'his', 'running', 'mate', '.', 'kanye', 'is', 'so', 'cute', ',', \"y'\", 'all', '.', '—', 'justin', 'timberlake', '(', 'oov', ')', 'august', 'qqq', ',', 'qqq', 'kanye', 'west', 'vs', 'donald', 'trump', 'for', 'president', '.', '#', 'vmas', 'qqq', '—', 'not', 'will', 'ferrell', '(', 'oov', ')', 'august', 'qqq', ',', 'qqq', '#', 'qqq', 'who', 'will', 'be', 'his', 'vice', 'president', '?', '—', 'brian', 'a.', 'hernandez', '(', 'oov', ')', 'august', 'qqq', ',', 'qqq', 'who', 'would', 'you', 'rather', 'have', 'for', 'oov', 'for', 'kanye', 'oov', 'for', 'donald', 'trump', 'qqq', '—', 'oov', '(', 'oov', ')', 'august', 'qqq', ',', 'qqq', 'this', 'is', 'ready', '.', 'qqq', '#', 'vmas', '—', 'tumblr', '(', 'oov', ')', 'august', 'qqq', ',', 'qqq', '<end>']\n",
      "reference summary ['<start>', 'mtv', \"'s\", 'star', '-', 'studded', ',', 'controversy', '-', 'filled', 'broadcast', 'generated', 'qqq', 'million', 'tweets', ',', 'up', 'from', 'qqq', 'million', 'in', 'qqq', '.', '<end>']\n",
      "decoded summary ['<start>', 'the', 'qqq', ',', ',', '<end>']\n",
      "3.12683\n"
     ]
    }
   ],
   "source": [
    "summary_info = results[0]\n",
    "triplets = get_text_triplets(batch, summary_info, preprocessor)\n",
    "for i,(text, reference_summary, decoded_summary) in enumerate(triplets):\n",
    "    loss = summary_info[2][i]\n",
    "    print(\"text\", text)\n",
    "    print(\"reference summary\", reference_summary)\n",
    "    print(\"decoded summary\", decoded_summary)\n",
    "    print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_info = results[0]\n",
    "i = 0\n",
    "\n",
    "triplets = get_text_triplets(batch, summary_info, preprocessor)\n",
    "\n",
    "text, decoded_summary, reference_summary = triplets[i]\n",
    "attentions, p_gens = [[float(f) for f in vector[1:-1]] for vector in summary_info[4][i][:-1]], [float(0) for j in range(len(decoded_summary)-1)]\n",
    "\n",
    "produce_attention_visualization_file('graphs/attn_vis_data.json', text, decoded_summary, \" \".join(reference_summary), attentions, p_gens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "produce_batch_summary_files(batch, generator_model, \"data\", beam_size=BEAM_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
