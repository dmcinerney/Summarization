{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from PICOHelper import get_pico_datasets\n",
    "from NewsroomHelper import get_newsroom_datasets\n",
    "from SummarizationModelStructures import TextEncoder, ContextVectorNN, VocubularyDistributionNN\n",
    "from utils import get_text_matrix, DataLoader\n",
    "from pytorch_helper import ModelManipulator, plot_learning_curves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training parameters\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 1\n",
    "LEARNING_RATE = 1e-3\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "print(USE_CUDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# pico_dataset_train, pico_dataset_dev, pico_dataset_test = get_pico_datasets()\n",
    "newsroom_dataset_train, newsroom_dataset_dev, newsroom_dataset_test = get_newsroom_datasets()\n",
    "word_vectors = newsroom_dataset_train.word_vectors\n",
    "start_index = newsroom_dataset_train.word_indices['<start>']\n",
    "end_index = newsroom_dataset_train.word_indices['<end>']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratorModel(nn.Module):\n",
    "    def __init__(self, word_vectors, start_index, end_index, num_hidden1=None, num_hidden2=None, with_coverage=False):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.word_vectors = word_vectors\n",
    "        num_features = len(self.word_vectors[0])\n",
    "        num_vocab = len(self.word_vectors)\n",
    "        self.start_index = start_index\n",
    "        self.end_index = end_index\n",
    "        if num_hidden1 is None:\n",
    "            num_hidden1 = num_features//2\n",
    "        if num_hidden2 is None:\n",
    "            num_hidden2 = num_features//2\n",
    "        self.with_coverage = with_coverage\n",
    "        \n",
    "        self.text_encoder = TextEncoder(num_features, num_hidden1, bidirectional=True)\n",
    "        self.summary_decoder = nn.LSTMCell(num_features, num_hidden1)\n",
    "        self.context_nn = ContextVectorNN(num_hidden1*3, num_hidden2, with_coverage=with_coverage)\n",
    "        self.vocab_nn = VocubularyDistributionNN(num_hidden1*3, num_vocab)\n",
    "        \n",
    "    def forward(self, text, text_length, summary=None, summary_length=None, generate_algorithm='greedy'):\n",
    "        # get batch with vectors from index batch\n",
    "        max_length = text.size(1)\n",
    "        text = [get_text_matrix(example[:text_length[i]], self.word_vectors, max_length)[0].unsqueeze(0) for i,example in enumerate(text)]\n",
    "        text = torch.cat(text, 0)\n",
    "        \n",
    "        # run text through lstm encoder\n",
    "        text_states, (h, c) = self.text_encoder(text, text_length)\n",
    "        \n",
    "        #initialize\n",
    "        coverage = torch.zeros((text_states.size(0), 1, text_states.size(1)), device=text_states.device)\\\n",
    "                   if self.with_coverage else None\n",
    "        loss = 0\n",
    "        if summary is None:\n",
    "            if generate_algorithm == 'greedy':\n",
    "                return self.forward_generate_greedy(text_states, h, c, coverage, loss)\n",
    "            else:\n",
    "                raise Exception\n",
    "        else:\n",
    "            return self.forward_supervised(text_states, h, c, coverage, loss, summary, summary_length)\n",
    "            \n",
    "    def forward_generate_greedy(self, text_states, h, c, coverage, loss):\n",
    "        batch_length = text_states.size(0)\n",
    "        valid_indices = torch.arange(batch_length, device=h.device)\n",
    "        summary = [torch.zeros((batch_length,1), device=h.device)+self.start_index]\n",
    "        summary_length = torch.zeros(batch_length, device=h.device)-1\n",
    "        i = 0\n",
    "        h, c = h[:,0], c[:,0]\n",
    "        while True:\n",
    "            summary_i = summary[-1]\n",
    "            \n",
    "            # take a time step\n",
    "            vocab_dist_i, h, c, coverage, log_prob = self.timestep(valid_indices, summary_i, text_states, h, c, coverage, loss)\n",
    "            \n",
    "            summary_ip1 = torch.zeros(batch_length, device=h.device).long()\n",
    "            summary_ip1[valid_indices] = torch.max(vocab_dist_i, 1)[1]\n",
    "            summary.append(summary_ip1.unsqueeze(-1))\n",
    "            ending = (summary_ip1[valid_indices] == self.end_index)\n",
    "            ended_indices = valid_indices[torch.nonzero(ending).squeeze(-1)]\n",
    "            valid_indices = valid_indices[torch.nonzero(ending == 0).squeeze(-1)]\n",
    "            i += 1\n",
    "            summary_length[ended_indices] = i\n",
    "            if (summary_length >= 0).sum() == summary_length.size(0) or i > 50000:\n",
    "                break\n",
    "            \n",
    "        return loss, torch.cat(summary, 1), summary_length\n",
    "            \n",
    "    \n",
    "    def forward_supervised(self, text_states, h, c, coverage, loss, summary, summary_length):\n",
    "        if summary_length is None:\n",
    "            raise Exception\n",
    "        h, c = h[:,0], c[:,0]\n",
    "        for i in range(summary.size(1)):\n",
    "            # get indices of instances that are not finished\n",
    "            valid_indices = torch.nonzero((summary_length-i-1) >= 0)[:,0]\n",
    "            summary_i = summary[valid_indices,i]\n",
    "            \n",
    "            # take a time step\n",
    "            vocab_dist_i, h, c, coverage, loss = self.timestep(valid_indices, summary_i, text_states, h, c, coverage, loss)\n",
    "            \n",
    "        return dict(loss=loss)\n",
    "        \n",
    "    def timestep(self, valid_indices, summary_i, text_states, h, c, coverage, loss):\n",
    "        # inputs at valid indices at position i\n",
    "        text_states_i = text_states[valid_indices]\n",
    "        summary_vec_i = get_text_matrix(summary_i, self.word_vectors, len(summary_i))[0]\n",
    "        h_i, c_i = h[valid_indices], c[valid_indices]\n",
    "        coverage_i = None if coverage is None else coverage[valid_indices]\n",
    "        \n",
    "        # Do forward pass\n",
    "        h_i, c_i = self.summary_decoder(summary_vec_i)\n",
    "        context_vector_i, attention_i = self.context_nn(text_states_i, h_i, coverage_i)\n",
    "        vocab_dist_i = self.vocab_nn(context_vector_i, h_i)\n",
    "        \n",
    "        # set new h, c, coverage, and loss\n",
    "        h[valid_indices], c[valid_indices] = h_i, c_i\n",
    "        if coverage is not None:\n",
    "            coverage[valid_indices] += attention_i\n",
    "        loss += -vocab_dist_i[torch.arange(summary_i.size(0)).long(),summary_i.long()].sum()\n",
    "        return vocab_dist_i, h, c, coverage, loss\n",
    "\n",
    "# text_encoder.num_hidden + summary_decoder.num_hidden\n",
    "def loss(loss):\n",
    "    return loss\n",
    "\n",
    "def error(loss):\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_model = GeneratorModel(word_vectors, start_index, end_index, num_hidden1=None, num_hidden2=None, with_coverage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(newsroom_dataset_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "optimizer = torch.optim.Adam(generator_model.parameters(),\n",
    "                             lr=LEARNING_RATE)\n",
    "model_manip = ModelManipulator(generator_model, optimizer, loss, error, use_cuda=USE_CUDA)\n",
    "train_stats, val_stats = model_manip.train(dataloader, NUM_EPOCHS, dataset_val=newsroom_dataset_dev, stats_every=10, verbose_every=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curves(training_values=train_stats, validation_values=val_stats, figure_name='summarization_training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = newsroom_dataset_train[:2]\n",
    "generator_model(batch['text'].cuda(), batch['text_length'].cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
